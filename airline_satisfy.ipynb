{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LoadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manage duplicate values\n",
    "df.duplicated().sum() \n",
    "# No duplicate values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for numeric columns\n",
    "Q1 = df[numeric_cols].quantile(0.25)\n",
    "Q3 = df[numeric_cols].quantile(0.75)\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outliers as those falling outside 1.5*IQR\n",
    "outliers = (df[numeric_cols] < (Q1 - 1.5 * IQR)) | (df[numeric_cols] > (Q3 + 1.5 * IQR))\n",
    "\n",
    "# Print the number of outliers per column\n",
    "print(outliers.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to treat 4 coloumns as outliers\n",
    "# Removing outlier is not a good option as it will affect the accuracy of the model due to high number of outliers\n",
    "# Select numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Create subplots with a number of rows equal to the number of numeric columns\n",
    "fig, axs = plt.subplots(len(numeric_cols), 1, figsize=(15, len(numeric_cols) * 2.5))\n",
    "\n",
    "# Ensure axs is iterable, even if there's only one numeric column\n",
    "if len(numeric_cols) == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "# Plot each numeric column in a separate subplot\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    sns.boxplot(data=df, x=col, ax=axs[i])\n",
    "    axs[i].set_title(f'Boxplot for {col}')\n",
    "    axs[i].set_xlabel('')  # Optional: remove x-axis label for cleaner plots\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining records after critical outlier removal: 102328\n",
      "Critical outliers per column:\n",
      " id                                      0\n",
      "Age                                     0\n",
      "Flight Distance                         0\n",
      "Inflight wifi service                   0\n",
      "Departure/Arrival time convenient       0\n",
      "Ease of Online booking                  0\n",
      "Gate location                           0\n",
      "Food and drink                          0\n",
      "Online boarding                         0\n",
      "Seat comfort                            0\n",
      "Inflight entertainment                  0\n",
      "On-board service                        0\n",
      "Leg room service                        0\n",
      "Baggage handling                        0\n",
      "Checkin service                         0\n",
      "Inflight service                        0\n",
      "Cleanliness                             0\n",
      "Departure Delay in Minutes           1106\n",
      "Arrival Delay in Minutes             1152\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for numeric columns\n",
    "Q1 = df[numeric_cols].quantile(0.25)\n",
    "Q3 = df[numeric_cols].quantile(0.90)\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define critical outliers as those falling outside 3*IQR (a more conservative threshold)\n",
    "critical_outliers = (df[numeric_cols] < (Q1 - 3 * IQR)) | (df[numeric_cols] > (Q3 + 3 * IQR))\n",
    "\n",
    "# Remove rows with critical outliers in any numeric column\n",
    "df_critical_clean = df[~critical_outliers.any(axis=1)]\n",
    "\n",
    "# Print the number of remaining records\n",
    "print(f\"Remaining records after critical outlier removal: {df_critical_clean.shape[0]}\")\n",
    "\n",
    "# Optionally, check how many critical outliers were removed per column\n",
    "critical_outliers_per_column = critical_outliers.sum()\n",
    "print(\"Critical outliers per column:\\n\", critical_outliers_per_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after capping: 103594\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Calculate the lower and upper bounds for capping (1st and 99th percentiles)\n",
    "lower_bound = df[numeric_cols].quantile(0.25)\n",
    "upper_bound = df[numeric_cols].quantile(0.75)\n",
    "\n",
    "# Cap the outliers\n",
    "df_capped = df.copy()\n",
    "df_capped[numeric_cols] = df_capped[numeric_cols].clip(lower=lower_bound, upper=upper_bound, axis=1)\n",
    "\n",
    "# Print the number of records to confirm no rows were removed\n",
    "print(f\"Number of records after capping: {df_capped.shape[0]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "##### We have 2 set of formats of data and we are processing removing outliers df_critical_clean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id       Age  Flight Distance  Inflight wifi service  \\\n",
      "0  0.137368 -1.746465        -0.731009               0.202820   \n",
      "1 -1.601222 -0.952391        -0.956660               0.202820   \n",
      "2  1.201371 -0.886218        -0.047035              -0.549933   \n",
      "3 -1.094555 -0.952391        -0.628714              -0.549933   \n",
      "4  1.448872  1.429833        -0.977721               0.202820   \n",
      "\n",
      "   Departure/Arrival time convenient  Ease of Online booking  Gate location  \\\n",
      "0                           0.616219                0.173147      -1.546322   \n",
      "1                          -0.694699                0.173147       0.018395   \n",
      "2                          -0.694699               -0.541512      -0.763963   \n",
      "3                           1.271677                1.602465       1.583112   \n",
      "4                          -0.039240                0.173147       0.018395   \n",
      "\n",
      "   Food and drink  Online boarding  Seat comfort  ...  Checkin service  \\\n",
      "0        1.350727        -0.185952      1.181976  ...         0.549902   \n",
      "1       -1.659721        -0.185952     -1.852623  ...        -1.823376   \n",
      "2        1.350727         1.296565      1.181976  ...         0.549902   \n",
      "3       -0.907109        -0.927210     -1.093973  ...        -1.823376   \n",
      "4        0.598115         1.296565      1.181976  ...        -0.241190   \n",
      "\n",
      "   Inflight service  Cleanliness  Departure Delay in Minutes  \\\n",
      "0          1.153829     1.306346                    0.518469   \n",
      "1          0.301456    -1.743610                   -0.429520   \n",
      "2          0.301456     1.306346                   -0.469019   \n",
      "3          0.301456    -0.981121                   -0.034524   \n",
      "4         -0.550917    -0.218632                   -0.469019   \n",
      "\n",
      "   Arrival Delay in Minutes  Gender      Customer Type   Type of Travel  \\\n",
      "0                  0.224547    Male     Loyal Customer  Personal Travel   \n",
      "1                 -0.242790    Male  disloyal Customer  Business travel   \n",
      "2                 -0.476458  Female     Loyal Customer  Business travel   \n",
      "3                 -0.125955  Female     Loyal Customer  Business travel   \n",
      "4                 -0.476458    Male     Loyal Customer  Business travel   \n",
      "\n",
      "      Class             satisfaction  \n",
      "0  Eco Plus  neutral or dissatisfied  \n",
      "1  Business  neutral or dissatisfied  \n",
      "2  Business                satisfied  \n",
      "3  Business  neutral or dissatisfied  \n",
      "4  Business                satisfied  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numeric columns\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = df_critical_clean.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df_critical_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Scale only the numeric columns\n",
    "sc = StandardScaler()\n",
    "df_scaled_numeric = sc.fit_transform(df_critical_clean[numeric_cols])\n",
    "\n",
    "# Convert scaled numeric data back to a DataFrame\n",
    "df_scaled_numeric = pd.DataFrame(df_scaled_numeric, columns=numeric_cols)\n",
    "\n",
    "# Combine scaled numeric columns with the original categorical columns\n",
    "df_scaled = pd.concat([df_scaled_numeric, df_critical_clean[categorical_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Optionally, if you need to encode the categorical columns, use this:\n",
    "# df_scaled = pd.get_dummies(df_scaled, columns=categorical_cols)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id       Age  Flight Distance  Inflight wifi service  \\\n",
      "0  0.137368 -1.746465        -0.731009               0.202820   \n",
      "1 -1.601222 -0.952391        -0.956660               0.202820   \n",
      "2  1.201371 -0.886218        -0.047035              -0.549933   \n",
      "3 -1.094555 -0.952391        -0.628714              -0.549933   \n",
      "4  1.448872  1.429833        -0.977721               0.202820   \n",
      "\n",
      "   Departure/Arrival time convenient  Ease of Online booking  Gate location  \\\n",
      "0                           0.616219                0.173147      -1.546322   \n",
      "1                          -0.694699                0.173147       0.018395   \n",
      "2                          -0.694699               -0.541512      -0.763963   \n",
      "3                           1.271677                1.602465       1.583112   \n",
      "4                          -0.039240                0.173147       0.018395   \n",
      "\n",
      "   Food and drink  Online boarding  Seat comfort  ...  Checkin service  \\\n",
      "0        1.350727        -0.185952      1.181976  ...         0.549902   \n",
      "1       -1.659721        -0.185952     -1.852623  ...        -1.823376   \n",
      "2        1.350727         1.296565      1.181976  ...         0.549902   \n",
      "3       -0.907109        -0.927210     -1.093973  ...        -1.823376   \n",
      "4        0.598115         1.296565      1.181976  ...        -0.241190   \n",
      "\n",
      "   Inflight service  Cleanliness  Departure Delay in Minutes  \\\n",
      "0          1.153829     1.306346                    0.518469   \n",
      "1          0.301456    -1.743610                   -0.429520   \n",
      "2          0.301456     1.306346                   -0.469019   \n",
      "3          0.301456    -0.981121                   -0.034524   \n",
      "4         -0.550917    -0.218632                   -0.469019   \n",
      "\n",
      "   Arrival Delay in Minutes  Gender  Customer Type  Type of Travel  Class  \\\n",
      "0                  0.224547       1              0               1      2   \n",
      "1                 -0.242790       1              1               0      0   \n",
      "2                 -0.476458       0              0               0      0   \n",
      "3                 -0.125955       0              0               0      0   \n",
      "4                 -0.476458       1              0               0      0   \n",
      "\n",
      "   satisfaction  \n",
      "0             0  \n",
      "1             0  \n",
      "2             1  \n",
      "3             0  \n",
      "4             1  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Handle categorical columns\n",
    "# we have use Label Encoding here\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = df_critical_clean.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df_critical_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Initialize LabelEncoder for categorical columns\n",
    "label_encoders = {}\n",
    "df_encoded = df_critical_clean.copy()\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_critical_clean[col])\n",
    "    label_encoders[col] = le  # Store the encoder for inverse_transform if needed\n",
    "\n",
    "# Scale only the numeric columns\n",
    "sc = StandardScaler()\n",
    "df_scaled_numeric = sc.fit_transform(df_encoded[numeric_cols])\n",
    "\n",
    "# Convert scaled numeric data back to a DataFrame\n",
    "df_scaled_numeric = pd.DataFrame(df_scaled_numeric, columns=numeric_cols)\n",
    "\n",
    "# Combine scaled numeric columns with the encoded categorical columns\n",
    "df_final = pd.concat([df_scaled_numeric, df_encoded[categorical_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df_final.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of each column to ensure numeric types are correctly set\n",
    "print(df_final.dtypes)\n",
    "\n",
    "# If you have categorical columns, ensure they are encoded as numeric\n",
    "# (Already done before using One-Hot Encoding)\n",
    "\n",
    "# Recalculate the correlation matrix\n",
    "corr_matrix = df_final.corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Filter strong correlations\n",
    "threshold = 0.5  # Choose the threshold that makes sense for your use case\n",
    "strong_corrs = corr_matrix[abs(corr_matrix) > threshold]\n",
    "\n",
    "# Print strong correlations, excluding self-correlations (1.0)\n",
    "strong_corrs = strong_corrs[strong_corrs != 1.0].dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
    "print(\"Strong correlations (>|0.5|):\\n\", strong_corrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'Age', 'Flight Distance', 'Inflight wifi service', 'Departure/Arrival time convenient', 'Ease of Online booking', 'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction']\n"
     ]
    }
   ],
   "source": [
    "print(df_final.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Imbalance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the class distribution for the full dataset \n",
    "# Since data set is approximately balanced, we can use the same class distribution\n",
    "\n",
    "# class distribution for the full dataset\n",
    "class_distribution_full = df_final['satisfaction'].value_counts()\n",
    "\n",
    "# Plot \n",
    "plt.figure(figsize=(8, 6))\n",
    "class_distribution_full.plot(kind='bar', color='skyblue')\n",
    "plt.title('Class Distribution in Full Dataset')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    \n",
    "    'Ease of Online booking',\n",
    "    'Food and drink',\n",
    "    'Online boarding',\n",
    "    'Leg room service',\n",
    "    'Inflight wifi service',\n",
    "    'Flight Distance',\n",
    "    'Seat comfort',\n",
    "    'Inflight entertainment',\n",
    "    'On-board service',\n",
    "    'Cleanliness',\n",
    "    'Departure Delay in Minutes',\n",
    "    'Arrival Delay in Minutes',\n",
    "    'Customer Type',\n",
    "    'Type of Travel',\n",
    "    'Class'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Create a new DataFrame with selected features and the target variable\n",
    "X = df_final[selected_features]\n",
    "y = df_final['satisfaction']  #  target variable\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features if necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9440046907065377\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     11541\n",
      "           1       0.95      0.92      0.93      8925\n",
      "\n",
      "    accuracy                           0.94     20466\n",
      "   macro avg       0.94      0.94      0.94     20466\n",
      "weighted avg       0.94      0.94      0.94     20466\n",
      "\n",
      "SVM Confusion Matrix:\n",
      " [[11089   452]\n",
      " [  694  8231]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svm_model = SVC(kernel='rbf', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate SVM performance\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "svm_report = classification_report(y_test, y_pred_svm)\n",
    "svm_confusion_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"SVM Classification Report:\\n\", svm_report)\n",
    "print(\"SVM Confusion Matrix:\\n\", svm_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9502101045636666\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96     11541\n",
      "           1       0.96      0.93      0.94      8925\n",
      "\n",
      "    accuracy                           0.95     20466\n",
      "   macro avg       0.95      0.95      0.95     20466\n",
      "weighted avg       0.95      0.95      0.95     20466\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      " [[11155   386]\n",
      " [  633  8292]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Random Forest performance\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_report = classification_report(y_test, y_pred_rf)\n",
    "rf_confusion_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest Classification Report:\\n\", rf_report)\n",
    "print(\"Random Forest Confusion Matrix:\\n\", rf_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
